{"cells":[{"cell_type":"markdown","metadata":{"id":"NrOX4FkxNBVU"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1764445773447,"user":{"displayName":"Jaime Song","userId":"17898589237361390774"},"user_tz":480},"id":"38NRPIeNMwtb"},"outputs":[],"source":["import os\n","os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\" # keras-opt likes this for some reason (i forget why)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":13846,"status":"ok","timestamp":1764445787294,"user":{"displayName":"Jaime Song","userId":"17898589237361390774"},"user_tz":480},"id":"4Ur4n5_tM-xx","outputId":"b08c54c0-88e6-429f-b1bc-c0345462f0c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/kavinravi/keras-opt-mod\n","  Cloning https://github.com/kavinravi/keras-opt-mod to /tmp/pip-req-build-n1zdbl8r\n","  Running command git clone --filter=blob:none --quiet https://github.com/kavinravi/keras-opt-mod /tmp/pip-req-build-n1zdbl8r\n","  Resolved https://github.com/kavinravi/keras-opt-mod to commit e532f15678818a2f9328a69b0a90af08c0c9258c\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras-opt==0.0.7) (2.0.2)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (from keras-opt==0.0.7) (2.19.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from keras-opt==0.0.7) (1.16.3)\n","Requirement already satisfied: absl-py\u003e=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (25.9.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,\u003e=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (0.6.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (0.2.0)\n","Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (18.1.1)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (5.29.5)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (75.2.0)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (1.17.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (3.2.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (4.15.0)\n","Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (2.0.1)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (1.76.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (2.19.0)\n","Requirement already satisfied: keras\u003e=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (3.10.0)\n","Requirement already satisfied: h5py\u003e=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (3.15.1)\n","Requirement already satisfied: ml-dtypes\u003c1.0.0,\u003e=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-\u003ekeras-opt==0.0.7) (0.5.4)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras\u003e=3.5.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras\u003e=3.5.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras\u003e=3.5.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (0.18.0)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (3.4.4)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (3.11)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (2025.11.12)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (3.10)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (3.1.3)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard~=2.19.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (3.0.3)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (4.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich-\u003ekeras\u003e=3.5.0-\u003etensorflow-\u003ekeras-opt==0.0.7) (0.1.2)\n","Building wheels for collected packages: keras-opt\n","  Building wheel for keras-opt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-opt: filename=keras_opt-0.0.7-py3-none-any.whl size=11768 sha256=13d811ca81f6e114bb2a64d5b9ce951e0bd2a3b96f16b7e670befdb86eba63e2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-comilcol/wheels/ef/70/5e/03387a1cdcf63982b44bf8f8dd7cd454d097d7bc4e97f74831\n","Successfully built keras-opt\n","Installing collected packages: keras-opt\n","Successfully installed keras-opt-0.0.7\n"]}],"source":["# this is to get keras-opt since it's a gitub repo lol\n","!pip install git+https://github.com/kavinravi/keras-opt-mod"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":19893,"status":"ok","timestamp":1764445807191,"user":{"displayName":"Jaime Song","userId":"17898589237361390774"},"user_tz":480},"id":"33lx3AOyNAIf"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from plotnine import *\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras_opt import scipy_optimizer # this is the second order optimizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.compose import make_column_transformer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","metadata":{"id":"0F6xOU9mNW3J"},"source":["# Data"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":1821,"status":"ok","timestamp":1764445809013,"user":{"displayName":"Jaime Song","userId":"17898589237361390774"},"user_tz":480},"id":"Hy9Fl0ooNfyr","outputId":"39873b2d-18c0-4ef4-8185-4500cb062c46"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","RangeIndex: 76469 entries, 0 to 76468\n","Data columns (total 27 columns):\n"," #   Column                       Non-Null Count  Dtype  \n","---  ------                       --------------  -----  \n"," 0   index                        76469 non-null  int64  \n"," 1   date                         76469 non-null  object \n"," 2   return                       76469 non-null  float64\n"," 3   high_open_ratio              76469 non-null  float64\n"," 4   open_low_ratio               76469 non-null  float64\n"," 5   high_close_ratio             76469 non-null  float64\n"," 6   volatility_by_candle_number  76469 non-null  float64\n"," 7   weekday                      76469 non-null  int64  \n"," 8   volume                       76469 non-null  float64\n"," 9   candle_direction             76469 non-null  float64\n"," 10  earning_moment               76469 non-null  int64  \n"," 11  rolling_std_return           76469 non-null  float64\n"," 12  true_range                   76469 non-null  float64\n"," 13  ATR                          76469 non-null  float64\n"," 14  volume_delta                 76469 non-null  float64\n"," 15  volume_spike                 76469 non-null  int64  \n"," 16  volume_per_range             76469 non-null  float64\n"," 17  vix                          76469 non-null  float64\n"," 18  amzn_vix_proxy               76469 non-null  float64\n"," 19  iv_delta                     76469 non-null  float64\n"," 20  put_spread                   76469 non-null  float64\n"," 21  call_spread                  76469 non-null  float64\n"," 22  rsi                          76469 non-null  float64\n"," 23  macd                         76469 non-null  float64\n"," 24  tokenId                      76469 non-null  int64  \n"," 25  open_next                    76469 non-null  float64\n"," 26  close_next                   76469 non-null  float64\n","dtypes: float64(21), int64(5), object(1)\n","memory usage: 15.8+ MB\n"]}],"source":["data2 = pd.read_csv('https://raw.githubusercontent.com/kavinravi/CPSC_393/refs/heads/main/datasets/features_with_next_prices_clean.csv') # modify this to make it a google colab filepath\n","data2.dropna(inplace = True)\n","data2.reset_index(inplace = True)\n","data2.info()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":161,"status":"ok","timestamp":1764445809180,"user":{"displayName":"Jaime Song","userId":"17898589237361390774"},"user_tz":480},"id":"5LKQ3wUhNpGV"},"outputs":[],"source":["X = data2.drop(columns=['index', 'date', 'candle_direction', 'tokenId', 'open_next', 'close_next']) # useless columns we don't need\n","y = data2['open_next'].values.reshape(-1, 1)\n","contin = ['volatility_by_candle_number', 'volume',\n","          'rolling_std_return', 'true_range', 'ATR', 'volume_delta', 'volume_per_range', 'vix',\n","          'amzn_vix_proxy', 'iv_delta', 'put_spread', 'call_spread', 'rsi', 'macd', 'return']\n","categorical = ['weekday', 'earning_moment', 'volume_spike']\n","\n","\n","preprocessor = make_column_transformer(\n","    (OneHotEncoder(sparse_output=False, drop=\"first\"), categorical),\n","    remainder=\"passthrough\"\n",")\n","\n","tf.keras.backend.set_floatx('float64') # second order optimizers operate a LOT better with float64 precision as opposed to default float32\n","# X_train, X_test, y_train_raw, y_test_raw = train_test_split(X, y, test_size=0.2, random_state=3619) # normal tts doesn't take time series into account so it randomly shuffles \u0026 splits\n","n = len(X)\n","split_idx = int(n * 0.8)   # 80% train / 20% test for chronological split, aka a manual train/test split\n","\n","\n","\n","X_train_raw = X[:split_idx] # the chronological train/test split from above\n","X_test_raw  = X[split_idx:]\n","y_train_raw = y[:split_idx]\n","y_test_raw  = y[split_idx:]\n","\n","\n","\n","scaler = StandardScaler()\n","y_train = scaler.fit_transform(y_train_raw)\n","y_test = scaler.transform(y_test_raw)\n","X_train = preprocessor.fit_transform(X_train_raw)\n","X_test = preprocessor.transform(X_test_raw)\n","\n","\n","X_train64 = X_train.astype('float64') # changing values to float64 for reasons mentioned above\n","X_test64 = X_test.astype('float64')\n","y_train64 = y_train.astype('float64')\n","y_test64 = y_test.astype('float64')\n","num_features = X_train.shape[1]"]},{"cell_type":"markdown","metadata":{"id":"o5aS-7gZN6iG"},"source":["# Feedforward Model"]},{"cell_type":"markdown","metadata":{"id":"L94mSi_FUuit"},"source":["## w/ normal optimizer"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1764445809211,"user":{"displayName":"Jaime Song","userId":"17898589237361390774"},"user_tz":480},"id":"d_GSMQRPUzgg"},"outputs":[],"source":["tf.keras.backend.clear_session() # if necessary to remove float64\n","tf.keras.backend.set_floatx('float32')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":68936,"status":"ok","timestamp":1764445878148,"user":{"displayName":"Jaime Song","userId":"17898589237361390774"},"user_tz":480},"id":"zFNgGzIyU1le","outputId":"beb0b508-4d72-40a7-922d-90081bee4eb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","239/239 [==============================] - 6s 21ms/step - loss: 0.0271 - mae: 0.0853 - val_loss: 0.0037 - val_mae: 0.0403\n","Epoch 2/20\n","239/239 [==============================] - 5s 19ms/step - loss: 0.0031 - mae: 0.0353 - val_loss: 0.0017 - val_mae: 0.0213\n","Epoch 3/20\n","239/239 [==============================] - 5s 20ms/step - loss: 0.0023 - mae: 0.0293 - val_loss: 0.0013 - val_mae: 0.0173\n","Epoch 4/20\n","239/239 [==============================] - 5s 19ms/step - loss: 0.0021 - mae: 0.0289 - val_loss: 0.0013 - val_mae: 0.0157\n","Epoch 5/20\n","239/239 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0250 - val_loss: 0.0011 - val_mae: 0.0145\n","Epoch 6/20\n","239/239 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0250 - val_loss: 9.8369e-04 - val_mae: 0.0188\n","Epoch 7/20\n","239/239 [==============================] - 2s 10ms/step - loss: 0.0015 - mae: 0.0233 - val_loss: 0.0012 - val_mae: 0.0227\n","Epoch 8/20\n","239/239 [==============================] - 3s 12ms/step - loss: 0.0016 - mae: 0.0246 - val_loss: 0.0013 - val_mae: 0.0186\n","Epoch 9/20\n","239/239 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0227 - val_loss: 0.0011 - val_mae: 0.0149\n","Epoch 10/20\n","239/239 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0218 - val_loss: 0.0015 - val_mae: 0.0166\n","Epoch 11/20\n","239/239 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0214 - val_loss: 9.3782e-04 - val_mae: 0.0144\n","Epoch 12/20\n","239/239 [==============================] - 3s 11ms/step - loss: 0.0011 - mae: 0.0197 - val_loss: 0.0010 - val_mae: 0.0151\n","Epoch 13/20\n","239/239 [==============================] - 4s 17ms/step - loss: 0.0010 - mae: 0.0187 - val_loss: 8.4726e-04 - val_mae: 0.0138\n","Epoch 14/20\n","239/239 [==============================] - 4s 18ms/step - loss: 0.0011 - mae: 0.0193 - val_loss: 8.6647e-04 - val_mae: 0.0136\n","Epoch 15/20\n","239/239 [==============================] - 6s 24ms/step - loss: 9.3993e-04 - mae: 0.0185 - val_loss: 8.4754e-04 - val_mae: 0.0134\n","Epoch 16/20\n","239/239 [==============================] - 4s 17ms/step - loss: 8.0959e-04 - mae: 0.0169 - val_loss: 7.3679e-04 - val_mae: 0.0125\n","Epoch 17/20\n","239/239 [==============================] - 2s 10ms/step - loss: 7.1729e-04 - mae: 0.0162 - val_loss: 7.6961e-04 - val_mae: 0.0166\n","Epoch 18/20\n","239/239 [==============================] - 3s 12ms/step - loss: 6.5347e-04 - mae: 0.0154 - val_loss: 9.3251e-04 - val_mae: 0.0141\n","Epoch 19/20\n","239/239 [==============================] - 2s 10ms/step - loss: 6.1563e-04 - mae: 0.0148 - val_loss: 7.0280e-04 - val_mae: 0.0126\n","Epoch 20/20\n","239/239 [==============================] - 2s 10ms/step - loss: 5.7967e-04 - mae: 0.0148 - val_loss: 6.8551e-04 - val_mae: 0.0128\n"]}],"source":["model3 = keras.Sequential([\n","    keras.layers.Dense(512, activation='relu', input_shape=(num_features,)),\n","    keras.layers.Dense(256, activation='relu'),\n","    keras.layers.Dense(512, activation='relu'),\n","    keras.layers.Dense(1, activation='linear')\n","])\n","\n","model3.compile(loss='mean_squared_error',\n","               optimizer='adam',\n","               metrics=['mae'])\n","\n","history_mlp_adam = model3.fit(X_train, y_train,\n","                           epochs=20, verbose=1, batch_size=256, # larger batch size for larger datasets... right?\n","                           validation_data=(X_test, y_test))"]},{"cell_type":"markdown","metadata":{"id":"qNZXMoqpUx2L"},"source":["## w/ L-BFGS"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1764445878155,"user":{"displayName":"Jaime Song","userId":"17898589237361390774"},"user_tz":480},"id":"rz5XZfWJN6Rl"},"outputs":[],"source":["# just a caution cell to make sure stuff is in float64 format\n","tf.keras.backend.clear_session()\n","tf.keras.backend.set_floatx('float64')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":161794,"status":"ok","timestamp":1764446039951,"user":{"displayName":"Jaime Song","userId":"17898589237361390774"},"user_tz":480},"id":"cTrrePqnOATR","outputId":"364f111c-d06f-4b79-9991-c23457e69f43"},"outputs":[{"name":"stdout","output_type":"stream","text":["30/30 [==============================] - 162s 5s/step - loss: 0.0022 - mae: 0.0267 - val_loss: 5.0471e-04 - val_mae: 0.0156\n"]}],"source":["with tf.device('/CPU:0'): # needed bcs I cannot change GPU settings during runtime, and GPUs suck with float64 and CPU is actually faster lol\n","    model4 = keras.Sequential([\n","        keras.layers.Dense(256, activation='relu', input_shape=(num_features,)),\n","        keras.layers.Dense(128, activation='relu'),\n","        keras.layers.Dense(64, activation='relu'),\n","        keras.layers.Dense(1, activation='linear')\n","    ])\n","\n","    model4.compile(loss='mean_squared_error',\n","                metrics=['mae'])\n","\n","    model4.train_function = scipy_optimizer.make_train_function(\n","        model4,\n","        method=\"L-BFGS-B\",            # top-level OK\n","        maxiter=300,                  # top-level OK\n","    )\n","\n","    history_mlp_lfbgs = model4.fit(X_train64, y_train64,\n","                            epochs=1, verbose=1, batch_size=2048,\n","                            validation_data=(X_test64, y_test64))\n","    second_order_mlp = history_mlp_lfbgs.history"]},{"cell_type":"markdown","metadata":{"id":"X4rboipwBDWV"},"source":["## w/ Trust-NCG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":0},"id":"3SE8ISmBBF5U"},"outputs":[{"name":"stdout","output_type":"stream","text":["\r      0/Unknown - 0s 0s/step - loss: 1.1002"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/scipy/optimize/_minimize.py:806: OptimizeWarning: Unknown solver options: xtol\n"]},{"name":"stdout","output_type":"stream","text":["     29/Unknown - 1s 39ms/step - loss: 0.0012         Current function value: 0.001172\n","         Iterations: 235\n","         Function evaluations: 237\n","         Gradient evaluations: 200\n","         Hessian evaluations: 1907\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/scipy/optimize/_minimize.py:806: RuntimeWarning: A bad approximation caused failure to predict improvement.\n"]},{"name":"stdout","output_type":"stream","text":["30/30 [==============================] - 4776s 159s/step - loss: 0.0012 - mae: 0.0194 - val_loss: 0.0014 - val_mae: 0.0141\n"]}],"source":["with tf.device('/CPU:0'): # needed bcs I cannot change GPU settings during runtime\n","    model5 = keras.Sequential([\n","        keras.layers.Dense(256, activation='relu', input_shape=(num_features,)),\n","        keras.layers.Dense(128, activation='relu'),\n","        keras.layers.Dense(64, activation='relu'),\n","        keras.layers.Dense(1, activation='linear')\n","    ])\n","\n","    model5.compile(loss='mean_squared_error',\n","                metrics=['mae'])\n","\n","    model5.train_function = scipy_optimizer.make_train_function(\n","        model5,\n","        method=\"trust-ncg\",            # top-level OK\n","        maxiter=300,\n","        gtol=1e-05,\n","        xtol=1e-08\n","    )\n","\n","    history_ncg_stocks = model5.fit(X_train64, y_train64,\n","                            epochs=1, verbose=1,\n","                            batch_size=2048,\n","                            validation_data=(X_test64, y_test64))\n","    trust_ncg_stocks = history_ncg_stocks.history"]},{"cell_type":"markdown","metadata":{"id":"j6GFJvfQOQUO"},"source":["## Performance Metrics\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"e8rl3uLwOTEM"},"outputs":[{"name":"stdout","output_type":"stream","text":["L-BFGS Metrics:\n"]},{"ename":"NameError","evalue":"name 'second_order_stocks' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3696302107.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# self explanatory... right?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L-BFGS Metrics:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training Loss: {second_order_stocks[\"loss\"]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training MAE: {second_order_stocks[\"mae\"]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Validation Loss: {second_order_stocks[\"val_loss\"]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'second_order_stocks' is not defined"]}],"source":["# self explanatory... right?\n","print(\"L-BFGS Metrics:\")\n","print(f'Training Loss: {second_order_stocks[\"loss\"]}')\n","print(f'Training MAE: {second_order_stocks[\"mae\"]}')\n","print(f'Validation Loss: {second_order_stocks[\"val_loss\"]}')\n","print(f'Validation MAE: {second_order_stocks[\"val_mae\"]}')\n","print(\"\\n\")\n","print(\"Trust-NCG Metrics:\")\n","print(f'Training Loss: {trust_ncg_stocks[\"loss\"]}')\n","print(f'Training MAE: {trust_ncg_stocks[\"mae\"]}')\n","print(f'Validation Loss: {trust_ncg_stocks[\"val_loss\"]}')\n","print(f'Validation MAE: {trust_ncg_stocks[\"val_mae\"]}')"]},{"cell_type":"markdown","metadata":{"id":"j3_o2R10BZEO"},"source":["## Actual vs Predicted Values"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6BivbH-2Ba78"},"outputs":[],"source":["y_pred_adam   = model3.predict(X_test.astype(np.float32))        # likely float32\n","y_pred_lbfgs  = model4.predict(X_test64)                          # float64\n","y_pred_ncg    = model5.predict(X_test64)                          # float64\n","\n","# inverse transform so values are in original scale\n","y_test_orig = scaler.inverse_transform(y_test64.reshape(-1,1)).ravel()\n","y_pred_adam_orig = scaler.inverse_transform(y_pred_adam.astype(np.float64)).ravel()\n","y_pred_lbfgs_orig = scaler.inverse_transform(y_pred_lbfgs).ravel()\n","y_pred_ncg_orig = scaler.inverse_transform(y_pred_ncg).ravel()\n","\n","N = len(y_test_orig)\n","idx = np.arange(N)\n","# pick first n samples to plot\n","n_plot = 500\n","idx_sub = idx[:n_plot]\n","\n","plt.figure(figsize=(10,5))\n","plt.plot(idx_sub, y_test_orig[idx_sub], label='Actual', linewidth=1)\n","plt.plot(idx_sub, y_pred_adam_orig[idx_sub], label='Predicted – Adam', linewidth=1, linestyle='--')\n","plt.plot(idx_sub, y_pred_lbfgs_orig[idx_sub], label='Predicted – L-BFGS', linewidth=1, linestyle=':')\n","plt.plot(idx_sub, y_pred_ncg_orig[idx_sub], label='Predicted – Trust-NCG', linewidth=1, linestyle='--')\n","plt.legend()\n","plt.title(\"Actual vs Predicted (first {} samples)\".format(n_plot))\n","plt.xlabel(\"Test sample index\")\n","plt.ylabel(\"Target value\")\n","plt.show()\n","\n","plt.figure(figsize=(10,5))\n","plt.plot(idx_sub, y_test[idx_sub], label='Actual', linewidth=1)\n","plt.plot(idx_sub, y_pred_adam[idx_sub], label='Predicted – Adam', linewidth=1, linestyle='--')\n","plt.plot(idx_sub, y_pred_lbfgs[idx_sub], label='Predicted – L-BFGS', linewidth=1, linestyle=':')\n","plt.plot(idx_sub, y_pred_ncg[idx_sub], label='Predicted – Trust-NCG', linewidth=1, linestyle='--')\n","plt.legend()\n","plt.title(\"Actual vs Predicted (first {} samples) (SCALED)\".format(n_plot))\n","plt.xlabel(\"Test sample index\")\n","plt.ylabel(\"Scaled Target value\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Q9D1sI1IAeZu"},"source":["# Long Short-Term Memory (LSTM)"]},{"cell_type":"markdown","metadata":{"id":"jt4OdpmjNTLg"},"source":["## Define Sequence Lengths (optimized for larger dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lSIsoRzdM-nU"},"outputs":[],"source":["def create_sequences(X, y, seq_length):\n","    num_sequences = len(X) - seq_length\n","    num_features = X.shape[1] if len(X.shape) \u003e 1 else 1\n","\n","    # Pre-allocate arrays for memory efficiency\n","    X_seq = np.zeros((num_sequences, seq_length, num_features))\n","    y_seq = np.zeros(num_sequences)\n","\n","    for i in range(num_sequences):\n","        X_seq[i] = X[i:i+seq_length]\n","        y_seq[i] = y[i+seq_length]\n","\n","    return X_seq, y_seq\n","\n","# Define sequence length\n","SEQ_LEN = 78\n","\n","# Create sequences from your already-scaled feedforward data\n","X_train_lstm, y_train_lstm = create_sequences(X_train64, y_train64, SEQ_LEN)\n","X_test_lstm, y_test_lstm = create_sequences(X_test64, y_test64, SEQ_LEN)\n","\n","print(f\"Original shapes: X_train64={X_train64.shape}, y_train64={y_train64.shape}\")\n","print(f\"Sequence shapes: X_train_lstm={X_train_lstm.shape}, y_train_lstm={y_train_lstm.shape}\")\n","print(f\"num_features={num_features}\")"]},{"cell_type":"markdown","metadata":{"id":"SUtrSIkwNYtt"},"source":["## Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"v4cREgJ6NXq8"},"outputs":[],"source":["model_lstm = keras.Sequential([\n","    keras.layers.LSTM(64, return_sequences=False, input_shape=(SEQ_LEN, num_features)),\n","    keras.layers.Dense(32, activation='relu'),\n","    keras.layers.Dense(1)\n","])\n","\n","model_lstm.compile(\n","    optimizer='adam',\n","    loss='mse',\n","    metrics=['mae']\n",")\n","\n","# train\n","history_lstm = model_lstm.fit(\n","    X_train_lstm, y_train_lstm,\n","    epochs=10,\n","    batch_size=64,\n","    validation_data=(X_test_lstm, y_test_lstm),\n","    verbose=1\n",")\n","\n","# # predict\n","# y_pred_lstm = model_lstm.predict(X_test)\n","# print(\"Predictions generated.\")"]},{"cell_type":"markdown","metadata":{"id":"x7gz-BKiNbxl"},"source":["## L-BFGS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jN1MphvWNcgo"},"outputs":[],"source":["with tf.device('/CPU:0'):\n","    model_lstm_lbfgs = keras.Sequential([\n","        keras.layers.LSTM(64, return_sequences=False, input_shape=(SEQ_LEN, num_features)),\n","        keras.layers.Dense(32, activation='relu'),\n","        keras.layers.Dense(1)\n","    ])\n","\n","    model_lstm_lbfgs.compile(\n","        loss='mse',\n","        metrics=['mae']\n","    )\n","\n","    model_lstm_lbfgs.train_function = scipy_optimizer.make_train_function(\n","        model_lstm_lbfgs,\n","        method=\"L-BFGS-B\",\n","        maxiter=300\n","    )\n","    # train\n","    history_lstm_lbfgs = model_lstm_lbfgs.fit(\n","        X_train_lstm, y_train_lstm,\n","        epochs=1,\n","        batch_size=64, # must be much smaller than ffn due to memory constraints, increase as available\n","        validation_data=(X_test_lstm, y_test_lstm),\n","        verbose=1\n","    )\n","    lbfgs_lstm = history_lstm_lbfgs.history"]},{"cell_type":"markdown","metadata":{"id":"otKvPqyANfK8"},"source":["## Trust-NCG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"b318xio7Nf0B"},"outputs":[],"source":["with tf.device('/CPU:0'):\n","    model_lstm = keras.Sequential([\n","        keras.layers.LSTM(64, return_sequences=False, input_shape=(SEQ_LEN, num_features)),\n","        keras.layers.Dense(32, activation='relu'),\n","        keras.layers.Dense(1)\n","    ])\n","\n","    model_lstm.compile(\n","        loss='mse',\n","        metrics=['mae']\n","    )\n","\n","    model_lstm.train_function = scipy_optimizer.make_train_function(\n","        model_lstm,\n","        method=\"L-BFGS-B\",\n","        maxiter=300,\n","        gtol=1e-05,\n","        xtol=1e-08\n","    )\n","    # train\n","    history_lstm = model_lstm.fit(\n","        X_train_lstm, y_train_lstm,\n","        epochs=1,\n","        batch_size=2048,\n","        validation_data=(X_test_lstm, y_test_lstm),\n","        verbose=1\n","    )\n","    lbfgs_lstm = history_lstm.history"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}